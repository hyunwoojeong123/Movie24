# 자기주도 PJT

[toc]

## Google Colab 기반의 얼굴인식 입문 PJT

### Colab

> Jupyter NoteBook에 추가로 Python 소스코드를 Google의 클라우드 컴퓨팅 환경에서 GPU와 TPU를 무료로 사용할 수 있고 소스코드나 데이터를 Google Drive를 통해 불러오거나 저장할 수도 있는 개발 환경입니다.
>
> Cloud 기반이므로 별도의 설치과정이 필요 없으며 딥러닝, M/L, 데이터 사이언스 분야에서 사용하고 있습니다.

Colab에서는 재사용이 가능한 코드와 다양한 예제가 좌측의 `<>` 모양의 아이콘을 클릭하면 나옵니다. 이를 *코드 스니펫 창* 이라고 합니다.

![image-20201223120208238](자기주도 PJT.assets/image-20201223120208238.png)

#### OpenCV

> OpenCV는 무료로 공개된 컴퓨터 비전 라이브러리로써 대부분의 OS를 지원하며 C/C++프로그래밍 언어로 개발 되었으나 Python, Java 및 MATLAB에 바인딩 된 인터페이스가 있어 Window, Linux, Android 및 MacOS를 지원합니다.
>
> 영상 관련 라이브러리로서 사실상 표준의 지위를 가지고 있다고 할 수 있으며 조금이라도 영상처리가 들어간다면 필수적으로 사용하게 되는 라이브러리 입니다.
>
> 라이브러리에는 2500개가 넘는 최적화 된 알고리즘이 있으며 여기에는 클래식 및 최신 컴퓨터 비전과 머신 러닝 알고리즘이 모두 포함됩니다. 이 알고리즘은 얼굴을 감지하고 인식하고, 물체를 식별하고, 비디오에서 사람의 행동을 분류하고, 카메라 움직임을 추적하고, 물체의 3D 모델을 추출하고, 스테레오 카메라에서 3D 포인트 클라우드를 생성하고, 이미지를 연결하여 고해상도를 생성하는 데 사용될 수 있습니다.

OpenCV로 가공된 그래픽을 matplotlib를 사용해 이미지 출력

![image-20201223131507854](자기주도 PJT.assets/image-20201223131507854.png)

### Python기반 face_recognition

> 얼굴이 표시된 영역을 알아내는 `Face Recognition(얼굴인식)`
>
> GPU, TPU 가속이 제공되는 Google Colab상에서 Python 기반의 face_recognition패키지를 사용하여 여러 가지 얼굴인식 모델을 경험할 수 있습니다.

#### Face Detection

1. Google Colab에 `.ipynb`파일을 생성한 후  런타임유형을 `Python3/GPU`로 변경합니다.
2. 코드스니펫의 Google Drive연동코드를 추가한 후 링크를 클릭하여 Authorization code를 복사해 붙여 넣어 줍니다.
3. `pip install face_recognition`을 설치합니다.
4. 여러 사람의 얼굴이 들어있는 사진 한 장을 준비해 구글 드라이브에 올려놓고, 이미지 파일이 업로드 된 Google Drive의 경로명, 디렉터리 명, 파일명을 설정해 줍니다.

```python
#라이브러리불러오기
import cv2, os
import face_recognition as fr
from lPython.display import image,display
from matplotlib import pyplot as plt
```

5. face_recognition패키지의 기본 HOG(Histogram of Oriented Gradient) 모델을 사용해 얼굴감지를 하고 사각형을 그려줍니다.

> **얼굴감지**
>
> `face_recognition` 패키지에 기본 `HOG`(Histogram of Oriented Gradient) 모델을 사용해 얼굴을 감지하고, `openCV`의 drawing API를 이용해 사각형을 그려줍니다.
>
> **이미지 출력**
>
>  `matplotlib`, `openCV`을 이용해 가공된 `image`를 화면에 출력합니다.

``` python
#사진불러오기
image_path = '/gdrive/My Drive/colab/people.jpg'
image = fr.load_image_file(image_path)
#얼굴감지
face_locations = fr.face_locations(image)

for (top,right, bottom,left) in face_locations:
    #(그릴곳, 시작점, 끝점, 색, 두께)
    cv2.rectangle(image,(left,top), (right,bottom),(0,255,0),3)

#이미지 버퍼 출력
plt.rcParmas["figure.figsize"] = (16,16)
plt.imshow(image)
plt.show()
```

6. 아래와 같이 초록색 사각형이 그려졌다면 HOG모델을 사용해 얼굴을 잘 찾은것입니다.

![image-20201224131642894](자기주도 PJT.assets/image-20201224131642894.png)



#### Face Recognition

> 몇 장의 인식된 얼굴영역에서 데이터를 추출하여 여러 사진들이 동일한 사람의 사진인지를 확인하는 방법을 알아보겠습니다.
>
> ![image-20201223133527981](자기주도 PJT.assets/image-20201223133527981.png)
>
> 위와 같이 face_recognition 패키지에서는 인물사진에서 인식한 얼굴영역을 복사하여 라이브러리에서 사용하는 데이터구조로 encoding을 한 후 이 encoding된 데이터를 이용하여 동일인 여부를 확인합니다.
>
> 즉, 2장의 사진에서 encoding된 2개의 얼굴데이터를 face_distance()의 파라미터로 전달하여 두 사진간의 distance를 얻어내고, distance값이 **0.6**이상이면 타인으로 볼 수 있고 미만이면 동일인으로 볼 수 있습니다.
>
> 좀 더 엄격한 기준으로 동일인을 인식하고 싶으면 수치를 조금 낮춰 distance를 0.5를 기준으로 로직을 작성하면 됩니다.

1. `face_recognition`패키지에 있는 `face_location`함수로 얼굴의 위치를 알아내 이미지를 `crop`(*사진이나 그림의 불필요한 부분을 잘라냄*)합니다.

> 이미지를 crop할때 `slice(:)`를 사용하는데, 원본 이미지가 잘리기 때문에 `image`를 `tmp_image`로 복사해서 사용합니다.

```python
#이미지 불러오기
image_path = "/gdrive/My Drive/colab/face recognition/actors.jpg"
image = fr.load_image_file(image_path)

#이미지에서 얼굴만 crop하기
face_locations = fr.face_location(image)
actor_faces=[]
for (top, right, bottom, left) in face_locations:
    #원본 이미지 복사
    tmp_image = image[:]
    #이미지 크롭
    face_image = tmp_image[top:bottom,left:right]
    # 얼굴 저장
    actor_faces.append(face_image)

#크롭한 결과보기
plt.rcParmas["figure.figsize"] = (1,1)

for face in actor_faces:
    plt.imshow(face)
    plt.show()
```



![image-20201224131708294](자기주도 PJT.assets/image-20201224131708294.png)

2. 얼굴인식 테스트할 이미지도 똑같이 crop을 해줍니다.

```python
image_path = '/gdrive/My Drive/colab/face recognition/unknown.jpg'
image = fr.load_image_file(image_path)

face_locations = fr.face_locations(image)

for (top, right, bottom, left) in face_locations:
  unknown = image[top:bottom, left:right]

plt.rcParams['figure.figsize'] = (1, 1)
plt.imshow(unknown)
plt.show()
```

![image-20201224131733005](자기주도 PJT.assets/image-20201224131733005.png)



3. `crop`된 이미지를 `face_encodings`함수로 인코딩하여 저장합니다.

```python
#unknown을 인코딩
enc_unknown_face = fr.face_encodings(unknown)
#화면에 결과를 출력
plt.imshow(enc_unknown_face)
plt.show()
```

![image-20201223135751776](자기주도 PJT.assets/image-20201223135751776.png)

4. 인코딩된 데이터를 `face_distance`함수로 얼마나 유사한지를 구합니다.

> 등록된 얼굴들과 distance비교하기
>
> forloop를 돌면서 `face_distance` 함수를 이용해 비교합니다.

```python
for face in actor_faces:
  # 등록된 배우 얼굴 인코딩하기
  enc_actor_face = fr.face_encodings(face)
	# 박서준 얼굴과의 거리 비교
  distance = fr.face_distance(enc_actor_face, enc_unknown_face[0])
  # 사진 타이틀 지정 및 출력(distance수치를 포함한 얼굴 출력)
  plt.title('distance' + str(distance))
  plt.imshow(face)
  plt.show()
```

![image-20201224131753958](자기주도 PJT.assets/image-20201224131753958.png)

5. 보통 타인이라고 구분하는 기준을 `0.5~0.6`사이로 잡으며, 이 이상일 경우 타인이라고 판단합니다.



## 블록체인

> 블록체인은 관리 대상 `데이터`를 '블록'이라고 하는 소규모 데이터들이 `P2P`방식을 기반으로 생성된 체인 형태의 연결고리 기반 분산 데이터 저장 환경에 저장하여 누구라도 임의로 수정할 수 없고 누구나 변경의 결과를 열람할 수 있는 `분산 컴퓨팅 기술` 기반의 원장 관리 기술입니다.
>
> 근본적으로 분산 데이터 저장기술의 한 형태로, 지속적으로 변경되는 데이터를 모든 참여 노드에 기록한 변경 리스트로서 분산 노드의 운영자에 의한 임의 조작이 불가능하도록 고안되었습니다. `블록체인 기술`은 `비토코인`을 비롯한 대부분의 암호화폐 거래에도 사용됩니다. 암호화폐의 거래과정은 탈중앙화된 전자장부에 쓰이기 때문에 블록체인 소프트웨어를 실행하는 많은 사용자들의 각 컴퓨터에서 서버가 운영되어, 중앙에 존재하는 은행 없이 개인 간의 자유로운 거래가 가능합니다.

